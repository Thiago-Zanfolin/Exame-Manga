{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMggY6z1lu08"
      },
      "source": [
        "### **Exame de CT-213 (Inteligência Artificial para Robótica Móvel)**\n",
        "### **Alunos:** Marcelo Roncato Júnior, Rodrigo Jamundá Melo, Thiago Zanfolin\n",
        "### **Grupo:** 16\n",
        "\n",
        "# **Implementação de Rede Neural Convolucional para Classificação de Gêneros Musicais**\n",
        "### **Professor:** Marcos Ricardo Omena de Albuquerque Máximo\n",
        "\n",
        "**Instituto Tecnológico de Aeronáutica – ITA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZNyFo9Fs9js"
      },
      "source": [
        "# 1. Introdução\n",
        "\n",
        "Este notebook corresponde ao código-fonte do projeto \"Implementação de Rede Neural Convolucional para Classificação de Gêneros Musicais\", para o exame de CT-213 do grupo 16. O código foi feito no *Google Colaboratory* pela facilidade de implementação e didática de explicação.\n",
        "\n",
        "Foram desenvolvidas 2 arquiteturas de rede neural (*neural network*, NN): uma convolucional (*convolutional neural network*, CNN) e outra que une características de CNN e RNN (*residual neural networks*). Como *dataset*, foi utilizada a versão *small* do *Free Music Archive* (FMA-Small). FMA (https://freemusicarchive.org/) é uma plataforma que contém músicas de licença aberta produzidas por artistas independentes. A versão *small* do *dataset* (aproximadamente 7,2 GB) contém 8000 faixas de 30 segundos cada distribuídas em 8 gêneros (*Electronic*, *Experimental*, *Folk*, *Internacional*, *Instrumental*, *Hip-Hop*, *Rock* e *Pop*).\n",
        "\n",
        "Acima de cada célula, está a estimativa do tempo para ela rodar, considerando a utilização da GPU T4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlVkBfjTs_kr"
      },
      "source": [
        "# 2. Carregamento do *dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0nKVy-Ul5g5"
      },
      "source": [
        "A célula seguinte baixa e descompacta o *dataset*.\n",
        "\n",
        "Estimativa de tempo: 16 min (6 min para baixar e 10 min para descompactar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vceWJaAyioA8",
        "outputId": "8915f606-ccd4-4fdf-d0cf-13c7753ea148"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Baixar o dataset FMA small\n",
        "!wget https://os.unil.cloud.switch.ch/fma/fma_small.zip\n",
        "\n",
        "# Descompactar o dataset\n",
        "with zipfile.ZipFile(\"fma_small.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"fma_small\")\n",
        "\n",
        "# Remover arquivo zip para economizar espaço\n",
        "os.remove(\"fma_small.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG19-TjpP80I"
      },
      "source": [
        "Caso esteja dando erro na descompactação (se rodar muitas vezes a célula acima consecutivamente, isso pode acontecer), rodar a célula abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaLGO-xRxPvg"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"fma_small.zip\"): # Excluir arquivo caso esteja dando erro na descompactação do FMA-Small\n",
        "    os.remove(\"fma_small.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3aye8N3yFtO"
      },
      "source": [
        "A célula seguinte baixa e descompacta os metadados.\n",
        "\n",
        "Estimativa de tempo: 1 min 30 s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ailqSLvN6KV8",
        "outputId": "c8b41993-2c97-4458-ae0c-a059ad4ccad4"
      },
      "outputs": [],
      "source": [
        "# Baixar os metadados\n",
        "!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
        "\n",
        "# Descompactar os metadados\n",
        "with zipfile.ZipFile(\"fma_metadata.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"fma_metadata\")\n",
        "\n",
        "# Remover arquivo zip para economizar espaço\n",
        "os.remove(\"fma_metadata.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ6F-d_SAK6y"
      },
      "source": [
        "Os metadados fazem o mapeamento e descrição do *dataset* (ID da faixa, gênero, artista, álbum, licença, data de lançamento, características como timbre e BPM, etc.). Caso queira visualizar os arquivos para entender melhor, rode a próxima célula.\n",
        "\n",
        "Estimativa de tempo: instantâneo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeBSLsEv__WE",
        "outputId": "9c74cbbd-1364-419e-c8b9-a5ed7a80adbd"
      },
      "outputs": [],
      "source": [
        "# Listar os arquivos e subpastas da pasta fma_metadata\n",
        "for root, dirs, files in os.walk(\"fma_metadata\"):\n",
        "    for name in files:\n",
        "        print(os.path.join(root, name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSVNOkG1AY31"
      },
      "source": [
        "A próxima célula atribui à variável *tracks* o carregamento do arquivo CSV tracks.csv dos metadados em um *dataframe* Multiindex (estrutura de dados do Pandas com múltiplos níveis de indexação). Nesse caso, o *dataframe* possui 2 camadas de colunas.\n",
        "\n",
        "Estimativa de tempo: 4 s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7SZYqYDayFPk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# tracks carrega o arquivo CSV tracks.csv em um dataframe Multiindex com 2 camadas de colunas\n",
        "# A coluna 0 contém os IDs das faixas\n",
        "tracks = pd.read_csv('fma_metadata/fma_metadata/tracks.csv', header=[0, 1], index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE8A3kaW72oC"
      },
      "source": [
        "A célula seguinte testa algumas faixas aleatórias. Pode rodar várias vezes, caso queira ouvir diferentes gêneros.\n",
        "\n",
        "Estimativa de tempo: instantâneo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "QnJI9Iun71ob",
        "outputId": "bf9e73d0-f2f6-45cd-c3bc-2d9a492f9b51"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "import random\n",
        "\n",
        "# Carregar os IDs das faixas do FMA-small\n",
        "track_ids = tracks.loc[tracks[('set', 'subset')] == 'small'].index # Filtra os dados do subset 'small' do dataset, dentro da categoria 'set'. Assim,\n",
        "                                                                   # track_ids contém todos os IDs de faixas que estão no conjunto FMA-small\n",
        "\n",
        "# Mapeia ID da faixa <--> gênero musical principal de cada faixa\n",
        "track_genres = tracks.loc[track_ids][('track', 'genre_top')]\n",
        "\n",
        "# Pegar 3 IDs aleatórios\n",
        "sample_ids = random.sample(list(track_ids), 3)\n",
        "print(\"IDs de faixas escolhidas:\", sample_ids)\n",
        "\n",
        "for track_id in sample_ids:\n",
        "    folder = f\"{track_id:06d}\"[:3]  # Pega os 3 primeiros dígitos para navegar na pasta correta\n",
        "    filepath = f\"fma_small/fma_small/{folder}/{track_id:06d}.mp3\"\n",
        "\n",
        "    print(f\"\\nTocando faixa ID {track_id} — Gênero: {track_genres[track_id]}\")\n",
        "    display(Audio(filename=filepath))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx8AZvJe_w0q"
      },
      "source": [
        "# 3. Construção do 1º modelo (CNN)\n",
        "\n",
        "|**Camada**|**Tipo**|**Número de Filtros**|**Tamanho da Saída**|**Tamanho do Kernel**|**Stride**|**Função de Ativação**|\n",
        "|:------|:----------------|:--|:----|:---|:-|:------|\n",
        "|Entrada|Imagem (espectrograma)|-  |40x1024|-   |- |-      |\n",
        "|1      |Conv2D           |32  |40x1024x32|3x3 |1 |LeakyReLU   |\n",
        "|2      |Conv2D |64  |40x1024x64|5x5 |1 |LeakyReLU    |\n",
        "|3      |BatchNormalization           |- |40x1024x64|- |- |-   |\n",
        "|4      |AveragePooling2D |64 |20x512x64  |2x2 |2 |-      |\n",
        "|5      |Conv2D           |64|20x512x64  |3x3 |1 |LeakyReLU   |\n",
        "|6      |Conv2D     |128  |20x512x128   |5x5   |1 |LeakyReLU   |\n",
        "|7      |BatchNormalization    |-  |20x512x128   |-   |- |- |\n",
        "|8       |AveragePooling2D      |128 |10x256x128 |2x2 |2 |- |\n",
        "|9      |GlobalAveragePooling  |128  |128  |- |- |-|\n",
        "|10      |Dense (FC)  |- |50 |- |- |ReLU |\n",
        "|11     |Dense (FC)  |- |5 |- |- |softmax |\n",
        "\n",
        "<p align=\"center\">\n",
        "<b>Tabela 1</b>: arquitetura do modelo CNN. </p>\n",
        "\n",
        "Acurácia obtida no teste após treinamento: 0.65\n",
        "\n",
        "*Loss* obtida no teste após treinamento: 0.99\n",
        "\n",
        "Estimativa de tempo: 54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "av_ySctr_wh8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, activations, Input, regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "lambda_l2 = 0.016 # Parâmetros para regularização L2\n",
        "\n",
        "# Para facilitar entendimento dos comentários acima de cada camada da rede:\n",
        "# f: dimensões do filtro\n",
        "# s: dimensões de stride\n",
        "# nc': número de filtros\n",
        "\n",
        "def make_CNN_model(input_shape, output_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=input_shape))\n",
        "\n",
        "    # 1ª camada: Conv2D, nc' = 32, f = 3, s = 1, LeakyReLU\n",
        "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='linear'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # 2ª camada: Conv2D, nc' = 64, f = 5, s = 1, LeakyReLU\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='linear'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # 3ª camada: BatchNormalization\n",
        "    model.add(layers.BatchNormalization()) #\n",
        "\n",
        "    # 4ª camada: AveragePooling2D, f = 2, s = 2\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # 5ª camada: Conv2D, nc' = 64, f = 3, s = 1, LeakyReLU\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='linear'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # 6ª camada: Conv2D, nc' = 128, f = 5, s = 1, LeakyReLU, regularização L2\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='linear', kernel_regularizer=regularizers.l2(lambda_l2)))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # 7ª camada: BatchNormalization\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # 8ª camada: AveragePooling2D, f = 2, s = 2\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # 9ª camada: GlobalAveragePooling2D\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "\n",
        "    # 10ª camada: Fully-Conected, 50 neurônios, ReLU, regularização L2\n",
        "    model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(lambda_l2)))\n",
        "    model.add(layers.Dropout(0.5)) # Adicionar dropout, para reduzir overfitting\n",
        "\n",
        "    # 11ª camada: Fully-Conected, softmax\n",
        "    model.add(layers.Dense(output_dim, activation=activations.softmax))\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETgqjuqIU6My"
      },
      "source": [
        "# 4. Construção do 2º modelo (CNN + RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRhVE23pU0Ri"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, activations, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "def make_clash_model(input_shape, output_dim, kernel_dim=5, kernel_initial_num=32, rnn_cells=128, dropout=0.25):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=input_shape))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOyBvUjZwvgk"
      },
      "source": [
        "Exemplo \"completo\" gerado pelo GPT:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojY1sEpNVZAH"
      },
      "source": [
        "# 5. Definição de funções úteis para processamento dos dados e treinamento\n",
        "\n",
        "Estimativa de tempo: instantâneo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SwQMSEghwp39"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "FMA_DIR = '/content/fma_small/fma_small' # Caminho onde estão os arquivos .mp3 do FMA-small\n",
        "METADATA_PATH = '/content/fma_metadata/fma_metadata/tracks.csv' # Caminho para o arquivo tracks.csv\n",
        "TRAINING_DATA_DIR = '/content/training_data' # Caminho para os dados de treinamento\n",
        "TARGET_GENRES = ['Rock', 'Hip-Hop', 'Experimental', 'Folk', 'Pop']  # Gêneros de interesse\n",
        "SAMPLES_PER_GENRE = 1000  # Número de exemplos por gênero para balancear o dataset\n",
        "SPECTROGRAM_SHAPE = (40, 1024) # Tamanho fixo para o espectrogrmaa\n",
        "\n",
        "def get_metadata(path=METADATA_PATH):\n",
        "    \"\"\"\n",
        "    Lê o tracks.csv com dois níveis de cabeçalho (header=[0, 1])\n",
        "    (o arquivo tem colunas multi-indexadas)\n",
        "    Usa a coluna de índice (index_col=0) para que cada linha represente\n",
        "    uma faixa (track) identificada por seu ID numérico.\n",
        "\n",
        "    :param path: caminho até o arquivo tracks.csv\n",
        "    :type path: string\n",
        "    :return tracks: \"tabela\" com os metadados\n",
        "    :rtype: pd.MultiIndex\n",
        "    \"\"\"\n",
        "    tracks = pd.read_csv(METADATA_PATH, header=[0, 1], index_col=0)\n",
        "\n",
        "    return tracks\n",
        "\n",
        "def filter_tracks(tracks, genres=TARGET_GENRES):\n",
        "    \"\"\"\n",
        "    Filtra as faixas a partir da \"tabela\" de dados e do seu gênero\n",
        "\n",
        "    :param tracks: \"tabela\" com as faixas\n",
        "    :type tracks: pd.MultiIndex\n",
        "    :param genres: gêneros de interesse\n",
        "    :type genres: list\n",
        "    :return filtered_tracks: \"tabela\" de dados filtrada\n",
        "    :rtype: pd.MultiIndex\n",
        "    \"\"\"\n",
        "    # Filtra apenas as faixas do subset \"small\"\n",
        "    small_tracks = tracks[tracks[('set', 'subset')] == 'small']\n",
        "\n",
        "    # Remove faixas que não possuem um gênero principal definido (campo 'genre_top' vazio)\n",
        "    small_tracks = small_tracks.dropna(subset=[('track', 'genre_top')])\n",
        "\n",
        "    # Filtra apenas as faixas que pertencem aos gêneros definidos\n",
        "    filtered_tracks = small_tracks[small_tracks[('track', 'genre_top')].isin(TARGET_GENRES)]\n",
        "\n",
        "    return filtered_tracks\n",
        "\n",
        "def balance_genres(tracks, genres=TARGET_GENRES, max_samples=SAMPLES_PER_GENRE):\n",
        "    \"\"\"\n",
        "    Balanceia o número de faixas por gênero\n",
        "\n",
        "    :param tracks: \"tabela\" com as faixas (base de dados)\n",
        "    :type tracks: pd.MultiIndex\n",
        "    :param genres: gêneros de interesse\n",
        "    :type genres: list\n",
        "    :param max_samples: número máximo de faixas por gênero\n",
        "    :type max_samples: int\n",
        "    :return balanced_tracks: \"tabela\" de dados balanceada\n",
        "    :rtype: pd.MultiIndex\n",
        "    \"\"\"\n",
        "    balanced_tracks = []\n",
        "\n",
        "    # Filtra por um gênero de cada vez\n",
        "    for genre in genres:\n",
        "        genre_tracks = tracks[tracks[('track', 'genre_top')] == genre]\n",
        "\n",
        "        # Limita o tamanho de exemplos por gênero\n",
        "        num_samples = min(max_samples, len(genre_tracks))\n",
        "\n",
        "        # Sorteia aleatoriamente um número fixo de faixas para balancear o dataset\n",
        "        balanced_tracks.append(genre_tracks.sample(num_samples, random_state=42))\n",
        "\n",
        "    # Une os subconjuntos em um único dataframe\n",
        "    balanced_tracks = pd.concat(balanced_tracks)\n",
        "\n",
        "    return balanced_tracks\n",
        "\n",
        "def get_audio_path(track_id, base_dir=FMA_DIR):\n",
        "    \"\"\"\n",
        "    Converte o ID da faixa para o caminho do arquivo na base de dados\n",
        "\n",
        "    :param track_id: ID da faixa\n",
        "    :type track_id: int\n",
        "    :param base_dir: diretório base do dataset\n",
        "    :type base_dir: string\n",
        "    :return track_path: caminho do arquivo na base de dados\n",
        "    :rtype track_path: string\n",
        "    \"\"\"\n",
        "    id_formatted = f\"{track_id:06d}\"\n",
        "    track_path = os.path.join(base_dir, id_formatted[:3], f\"{id_formatted}.mp3\")\n",
        "\n",
        "    return track_path\n",
        "\n",
        "def audio_to_mel_spectrogram(file_path, duration=30, sr=22050, n_mels=SPECTROGRAM_SHAPE[0]):\n",
        "    \"\"\"\n",
        "    Converte a faixa em um espectrograma\n",
        "\n",
        "    :param file_path: arquivo da faixa\n",
        "    :type file_path: string\n",
        "    :param duration: duração da faixa em segundos\n",
        "    :type duration: int\n",
        "    :param sr: taxa de amostragem\n",
        "    :type sr: int\n",
        "    :n_mels: número de bandas\n",
        "    :type n_mels: int\n",
        "    :return mel_db: espectrograma em escala logarítimica processado\n",
        "    :rtype mel_db: pd.DataFrame\n",
        "    \"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, duration=duration, sr=sr)\n",
        "        mel = librosa.feature.melspectrogram(y=y, sr=SPECTROGRAM_SHAPE[1]//duration, n_mels=n_mels)\n",
        "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "        return mel_db\n",
        "\n",
        "    # Captura um erro em algum arquivo\n",
        "    except Exception as e:\n",
        "        print(f\"Erro em {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_training_data(genres):\n",
        "    \"\"\"\n",
        "    Processa os dados das faixas para treinamento\n",
        "\n",
        "    :param genres: gêneros de interesse\n",
        "    :type genres: list\n",
        "    :return X_train: input de treinamento\n",
        "    :rtype X_train: numpay array\n",
        "    :return X_test: input de avaliação\n",
        "    :rtype X_test: numpay array\n",
        "    :return y_train: output de treinamento\n",
        "    :rtype y_train: numpay array\n",
        "    :return y_test: output de avaliação\n",
        "    :rype y_test: numpay array\n",
        "    \"\"\"\n",
        "    # Listas para armazenar espectrogramas (X) e rótulos numéricos (y)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # Processa e filtra as faixas de áudio\n",
        "    tracks = get_metadata()\n",
        "    filtered_tracks = filter_tracks(tracks)\n",
        "    balanced_tracks = balance_genres(filtered_tracks)\n",
        "\n",
        "    # Dicionário para mapear cada gênero para um índice (ex: {'Rock': 0, 'Hip-Hop': 1, ...})\n",
        "    label_dict = {genre: idx for idx, genre in enumerate(genres)}\n",
        "\n",
        "    # Itera sobre cada faixa\n",
        "    for track_id, row in tqdm(balanced_tracks.iterrows(), total=balanced_tracks.shape[0]):\n",
        "        # Define o gênero da faixa\n",
        "        genre = row[('track', 'genre_top')]\n",
        "\n",
        "        # Converte o caminho do arquivo\n",
        "        file_path = get_audio_path(track_id)\n",
        "\n",
        "        # Extrai o espectrograma\n",
        "        spec = audio_to_mel_spectrogram(file_path)\n",
        "\n",
        "        # Pula a faixa se houver erro no processamento\n",
        "        if spec is None:\n",
        "            continue\n",
        "\n",
        "        # Ajusta o espectrograma para o tamanho correto\n",
        "        if spec.shape[1] < SPECTROGRAM_SHAPE[1]:\n",
        "            # Aplica padding se o espectrograma for menor que o esperado\n",
        "            padding_width = SPECTROGRAM_SHAPE[1] - spec.shape[1]\n",
        "            spec = np.pad(spec, ((0, 0), (0, padding_width)), mode='constant', constant_values=0)\n",
        "\n",
        "        elif spec.shape[1] > SPECTROGRAM_SHAPE[1]:\n",
        "            # Trunca se ele for maior\n",
        "            spec = spec[:, :SPECTROGRAM_SHAPE[1]]\n",
        "\n",
        "        # Normaliza os valores para [0, 1] (boa prática para CNNs)\n",
        "        spec = (spec - spec.min()) / (spec.max() - spec.min())\n",
        "\n",
        "        # Adiciona uma dimensão ao final (input shape (H, W, 1))\n",
        "        spec = spec[..., np.newaxis]\n",
        "\n",
        "        # Adiciona o espectrograma e o gênero aos dados de treinamento\n",
        "        X.append(spec)\n",
        "        y.append(label_dict[genre])\n",
        "\n",
        "    # Transforma a lista de espectrogramas em um numpy array\n",
        "    X = np.array(X)\n",
        "\n",
        "    # Transforma os rótulos (ex: [0, 1, 2]) em formato one-hot\n",
        "    y = to_categorical(np.array(y), num_classes=len(genres))\n",
        "\n",
        "    # Divide em 80% treino / 20% teste, com random_state fixo para reprodutibilidade\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def save_training_data(**data):\n",
        "    \"\"\"\n",
        "    Salva os dados de treinamento em um arquivo .npz\n",
        "\n",
        "    :param **data: dados de treinamento\n",
        "    :type **data: dict\n",
        "    :return void:\n",
        "    \"\"\"\n",
        "    # Cria o diretório caso ele não exista\n",
        "    if not os.path.exists(TRAINING_DATA_DIR):\n",
        "        os.makedirs(TRAINING_DATA_DIR)\n",
        "\n",
        "    # Salva o arquivo com os dados\n",
        "    data_filename = f\"data_{SPECTROGRAM_SHAPE[0]}_{SPECTROGRAM_SHAPE[1]}_{SAMPLES_PER_GENRE}.npz\"\n",
        "    np.savez(os.path.join(TRAINING_DATA_DIR, data_filename), **data)\n",
        "\n",
        "def get_training_data(genres=TARGET_GENRES):\n",
        "    \"\"\"\n",
        "    Carrega os dados de treinamento\n",
        "\n",
        "    :param genres: gêneros de interesse\n",
        "    :type genres: list\n",
        "    :return X_train: input de treinamento\n",
        "    :rtype X_train: numpy array\n",
        "    :return X_test: input de avaliação\n",
        "    :rtype X_test: numpy array\n",
        "    :return y_train: output de treinamento\n",
        "    :rtype y_train: numpy array\n",
        "    :return y_test: output de avaliação\n",
        "    :rtype y_test: numpy array\n",
        "    \"\"\"\n",
        "    # Busca e abre o arquivo com os dados\n",
        "    try:\n",
        "        data_filename = f\"data_{SPECTROGRAM_SHAPE[0]}_{SPECTROGRAM_SHAPE[1]}_{SAMPLES_PER_GENRE}.npz\"\n",
        "        data = np.load(os.path.join(TRAINING_DATA_DIR, data_filename))\n",
        "\n",
        "        return data['X_train'], data['X_test'], data['y_train'], data['y_test']\n",
        "\n",
        "    # Se o arquivo não existir, os dados são processados e o arquivo é criado\n",
        "    except FileNotFoundError:\n",
        "        X_train, X_test, y_train, y_test = process_training_data(genres)\n",
        "        save_training_data(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "def delete_training_data():\n",
        "    \"\"\"\n",
        "    Deleta os dados de treinamento\n",
        "\n",
        "    :return void:\n",
        "    \"\"\"\n",
        "    # Checa se o diretório existe\n",
        "    if not os.path.exists(TRAINING_DATA_DIR):\n",
        "        return\n",
        "\n",
        "    # Abre o diretório e deleta tudo\n",
        "    for filename in os.listdir(TRAINING_DATA_DIR):\n",
        "        filepath = os.path.join(TRAINING_DATA_DIR, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            os.remove(filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaxK0j-p894q"
      },
      "source": [
        "# 6. Treinamento e avaliação dos modelos CNN e CNN + RNN\n",
        "\n",
        "Caso queira deletar os dados de algum treinamento anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0Ib7xe1gxvL3"
      },
      "outputs": [],
      "source": [
        "delete_training_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWuXqfDpVivX"
      },
      "source": [
        "Execução do treinamento (comente/descomente os trechos indicados para alternar entre os 2 modelos de rede neural):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OQLc2ix6VWfY",
        "outputId": "6618b224-abfc-4764-d180-30e9e26a4b36"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "NUM_EPOCHS = 90\n",
        "BATCH_SIZE = 65\n",
        "\n",
        "def train_model(model, X_train, y_train, epochs, batch_size,\n",
        "                optimizer=tf.keras.optimizers.Adam,\n",
        "                loss_function=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics=['accuracy'],\n",
        "                validation_split=0.2,\n",
        "                is_verbose=False):\n",
        "    \"\"\"\n",
        "    Realiza o treinamento do modelo\n",
        "\n",
        "    :param model: modelo a ser treinado\n",
        "    :type model: tf.keras.model\n",
        "    :param X_train: input de treinamento\n",
        "    :type X_traind: np.array\n",
        "    :param y_train: output de treinamento\n",
        "    :type y_train: np.array\n",
        "    :param epochs: número de épocas de treinamento\n",
        "    :type epochs: int\n",
        "    :param batch_size: tamanho do batch\n",
        "    :type batch_size: int\n",
        "    :param optimizer: otimizador de compilação do modelo\n",
        "    :type optimizer: tf.keras.optimizers\n",
        "    :param loss_function: função de custo do modelo\n",
        "    :type loss_function: tf.keras.losses\n",
        "    :param metrics: métricas avaliadas\n",
        "    :type metrics: list\n",
        "    :param validation_split: fração do dataset de treinamento usado para validação\n",
        "    :type validation_split: float\n",
        "    :param is_verbose: controla se o treinamento é impresso na tela\n",
        "    :type is_verbose: bool\n",
        "    :return model: modelo treinado\n",
        "    :rtype model: tf.keras.model\n",
        "    :return history: histórico de treinamento\n",
        "    :rtype history: tf.keras.callbacks.History\n",
        "    \"\"\"\n",
        "\n",
        "    # Durante o treinamento, foi percebido que fazer um schedule da taxa de aprendizado melhorava o desempenho das redes\n",
        "    # Por tentativa e erro, chegou-se no fator 0.35 (OBS.: esse número não foi otimizado, por falta de tempo de processamento)\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "      monitor='val_loss',  # Métrica a ser monitorada\n",
        "      factor=0.35,         # Fator pelo qual a taxa de aprendizado (learning rate) será reduzida (nova_lr = lr * factor)\n",
        "      patience=5,          # Número de épocas sem melhoria após as quais a taxa de aprendizado será reduzida\n",
        "      min_lr=0.0001,       # Taxa de aprendizado mínima\n",
        "      mode='min',          # 'min' para val_loss (busca minimizar)\n",
        "      verbose=1            # 1 para imprimir mensagens quando a taxa de aprendizado for atualizada\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer=optimizer(),\n",
        "              loss=loss_function,\n",
        "              metrics=metrics)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                    validation_split=validation_split,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size, callbacks=[reduce_lr],\n",
        "                    verbose=is_verbose)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Avalia o treinamento do modelo\n",
        "\n",
        "    :param model: modelo a ser avaliado\n",
        "    :type model: tf.keras.model\n",
        "    :param X_test: input de avaliação\n",
        "    :type X_test: numpy array\n",
        "    :param y_test: output de avaliação\n",
        "    :type y_test: numpy array\n",
        "    :return test_loss: função de custo da avaliação\n",
        "    :rtype test_loss: float\n",
        "    :return test_acc: acurácia da avaliação\n",
        "    :rtyoe test_acc: float\n",
        "    \"\"\"\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "# -------------------------\n",
        "#   TREINAMENTO DAS REDES\n",
        "# -------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_training_data()\n",
        "\n",
        "# Para treinar o 1º modelo de rede, deixe as 4 linhas abaixo descomentadas:\n",
        "model_CNN = make_CNN_model(SPECTROGRAM_SHAPE + (1,), len(TARGET_GENRES))\n",
        "model_CNN.summary()\n",
        "model_CNN, history = train_model(model_CNN, X_train, y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, is_verbose=True)\n",
        "test_loss, test_acc = evaluate_model(model_CNN, X_test, y_test)\n",
        "model.save(\"model_CNN.h5\")\n",
        "\n",
        "# Para treinar o 2º modelo de rede, comente as 4 linhas acima e descomente as 4 linhas abaixo:\n",
        "# model_RNN_CNN = make_RNN_CNN_model(SPECTROGRAM_SHAPE + (1,), len(TARGET_GENRES))\n",
        "# model_RNN_CNN.summary()\n",
        "# model_RNN_CNN, history = train_model(model_RNN_CNN, X_train, y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, is_verbose=True)\n",
        "# test_loss, test_acc = evaluate_model(model_RNN_CNN, X_test, y_test)\n",
        "# model.save(\"model_CNN_RNN.h5\")\n",
        "\n",
        "print(f\"Acurácia no teste: {test_acc:.2f}\")\n",
        "\n",
        "# Gráfico de acurácia\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Validação')\n",
        "plt.title('Acurácia durante o treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "\n",
        "print(f\"Loss no teste: {test_loss:.2f}\")\n",
        "\n",
        "# Gráfico de loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Treino')\n",
        "plt.plot(history.history['val_loss'], label='Validação')\n",
        "plt.title('Loss durante o treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnr-sYHZAEhk"
      },
      "source": [
        "Matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "kHMSb-7NACmb",
        "outputId": "d3d9f790-99f2-4ea6-f7b1-9f31bb45fecd"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Escolher modelo para avaliação\n",
        "model = load_model(\"model_CNN.h5\")\n",
        "# model = load_model(\"model_CNN_RNN.h5\")\n",
        "\n",
        "# Previsões\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "y_true_labels = y_test.argmax(axis=1)\n",
        "\n",
        "# Matriz\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=TARGET_GENRES)\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydbgZwnwAKFj"
      },
      "source": [
        "Curvas ROC por classe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "T_sbbgKuAKdD",
        "outputId": "c74ee1d9-4d5a-432e-cd17-44e67ab80fa3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Binariza y_test se ainda não estiver\n",
        "y_true = y_test\n",
        "n_classes = y_test.shape[1]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"{TARGET_GENRES[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Curvas ROC por Gênero\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce7qpAUcAOyq"
      },
      "source": [
        "Curvas de precisão e revocação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bG1VfC0APIb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Relatório de classificação:\\n\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, target_names=TARGET_GENRES))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
